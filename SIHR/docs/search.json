[{"path":"/articles/intro.html","id":"examples","dir":"Articles","previous_headings":"","what":"Examples","title":"intro","text":"basic examples show solve common high-dimensional inference problems:","code":"library(SIHR)"},{"path":"/articles/intro.html","id":"linear-functional-in-linear-regression-model---1","dir":"Articles","previous_headings":"Examples","what":"Linear functional in linear regression model - 1","title":"intro","text":"Generate Data find truth linear functionals: example, linear functional involve intercept term, set intercept.loading=FALSE (default). users want include intercept term, please set intercept.loading=TRUE, truth1 = -0.5 + 1.5 = 1; truth2 = -0.5 - 1.25 = -1.75 Call LF model=\"linear\": ci method LF summary method LF","code":"set.seed(0) X = matrix(rnorm(100*120), nrow=100, ncol=120) y = -0.5 + X[,1] * 0.5 + X[,2] * 1 + rnorm(100) loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) ## consider the intercept.loading=FALSE truth1 = 0.5 * 1 + 1 * 1 truth2 = 0.5 * -0.5 + 1 * -1 truth = c(truth1, truth2) truth ## [1]  1.50 -1.25 Est = LF(X, y, loading.mat, model=\"linear\", intercept=TRUE, intercept.loading=FALSE, verbose=TRUE) ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ci(Est) ##   loading     lower     upper ## 1       1  1.111919  1.722561 ## 2       2 -1.529687 -1.020350 summary(Est) ## Call:  ## Inference for Linear Functional ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     ##        1      1.158      1.417     0.1558   9.098 0.000e+00 *** ##        2     -1.015     -1.275     0.1299  -9.813 9.924e-23 ***"},{"path":"/articles/intro.html","id":"linear-functional-in-linear-regression-model---2","dir":"Articles","previous_headings":"Examples","what":"Linear functional in linear regression model - 2","title":"intro","text":"Sometimes, may interested multiple linear functionals, separate loading. computationally efficient, can specify argument beta.init first, program can save time compute initial estimator repeatedly. Call LF model=\"linear\": ci method LF summary method LF","code":"set.seed(1) X = matrix(rnorm(100*120), nrow=100, ncol=120) y = -0.5 + X[,1:10] %*% rep(0.5, 10) + rnorm(100) loading.mat = matrix(0, nrow=120, ncol=10) for(i in 1:ncol(loading.mat)){   loading.mat[i,i] =  1 } library(glmnet) ## Loading required package: Matrix ## Loaded glmnet 4.1-4 cvfit = cv.glmnet(X, y, family = \"gaussian\", alpha = 1, intercept = TRUE, standardize = T) beta.init = as.vector(coef(cvfit, s = cvfit$lambda.min)) Est = LF(X, y, loading.mat, model=\"linear\", intercept=TRUE, beta.init=beta.init, verbose=TRUE) ## Computing LF for loading (1/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (2/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (3/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (4/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (5/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (6/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (7/10)...  ## The projection direction is identified at mu = 0.027257at step =5 ## Computing LF for loading (8/10)...  ## The projection direction is identified at mu = 0.027257at step =5 ## Computing LF for loading (9/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (10/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ci(Est) ##    loading       lower     upper ## 1        1  0.01511794 0.7789204 ## 2        2  0.17744949 1.2347802 ## 3        3  0.14589125 0.9074732 ## 4        4  0.05357240 0.7355096 ## 5        5  0.18122547 1.0292098 ## 6        6 -0.30397428 0.7048378 ## 7        7  0.33282671 0.9970891 ## 8        8  0.01564265 0.7708467 ## 9        9  0.46020627 1.0619827 ## 10      10  0.12026114 0.7637474 summary(Est) ## Call:  ## Inference for Linear Functional ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     ##        1     0.2698     0.3970     0.1949  2.0376 4.159e-02   * ##        2     0.4145     0.7061     0.2697  2.6178 8.849e-03  ** ##        3     0.4057     0.5267     0.1943  2.7109 6.711e-03  ** ##        4     0.2631     0.3945     0.1740  2.2679 2.333e-02   * ##        5     0.3773     0.6052     0.2163  2.7977 5.147e-03  ** ##        6     0.2730     0.2004     0.2574  0.7788 4.361e-01     ##        7     0.3664     0.6650     0.1695  3.9240 8.708e-05 *** ##        8     0.2911     0.3932     0.1927  2.0412 4.124e-02   * ##        9     0.5699     0.7611     0.1535  4.9577 7.133e-07 *** ##       10     0.2839     0.4420     0.1642  2.6926 7.091e-03  **"},{"path":"/articles/intro.html","id":"linear-functional-in-logistic-regression-model","dir":"Articles","previous_headings":"Examples","what":"Linear functional in logistic regression model","title":"intro","text":"Generate Data find truth linear functionals: Call LF model=\"logistic\" model=\"logistic_alter\": ci method LF summary method LF Call LF model=\"logistic_alter\": ci method LF summary method LF","code":"set.seed(0) X = matrix(rnorm(100*120), nrow=100, ncol=120) exp_val = -0.5 + X[,1] * 0.5 + X[,2] * 1 prob = exp(exp_val) / (1+exp(exp_val)) y = rbinom(100, 1, prob) ## loadings loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) ## consider the intercept.loading=TRUE truth1 = 0.5 * 1 + 1 * 1 truth2 = 0.5 * -0.5 + 1 * -1 truth = c(truth1, truth2) truth.prob = exp(truth) / (1 + exp(truth)) truth; truth.prob ## [1]  1.50 -1.25 ## [1] 0.8175745 0.2227001 ## model = \"logisitc\" Est = LF(X, y, loading.mat, model=\"logistic\", verbose=TRUE) ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## confidence interval for linear combination ci(Est) ##   loading      lower      upper ## 1       1  0.6393023  2.2699716 ## 2       2 -1.9644387 -0.5538893 ## confidence interval after probability transformation ci(Est, probability = TRUE) ##   loading     lower     upper ## 1       1 0.6545957 0.9063594 ## 2       2 0.1229875 0.3649625 summary(Est) ## Call:  ## Inference for Linear Functional ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     ##        1     0.8116      1.455     0.4160   3.497 0.0004709 *** ##        2    -0.8116     -1.259     0.3598  -3.499 0.0004666 *** ## model = \"logistic_alter\" Est = LF(X, y, loading.mat, model=\"logistic_alter\", verbose=TRUE) ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## confidence interval for linear combination ci(Est) ##   loading      lower      upper ## 1       1  0.6121908  2.1603820 ## 2       2 -1.8474229 -0.5201972 ## confidence interval after probability transformation ci(Est, probability = TRUE) ##   loading     lower     upper ## 1       1 0.6484404 0.8966350 ## 2       2 0.1361758 0.3728061 summary(Est) ## Call:  ## Inference for Linear Functional ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     ##        1     0.7597      1.386     0.3950   3.510 0.0004481 *** ##        2    -0.7597     -1.184     0.3386  -3.496 0.0004717 ***"},{"path":"/articles/intro.html","id":"individualized-treatment-effect-in-linear-regression-model","dir":"Articles","previous_headings":"Examples","what":"Individualized Treatment Effect in linear regression model","title":"intro","text":"Generate Data find truth linear functionals: Call ITE model=\"linear\": ci method ITE summary method ITE","code":"set.seed(0) ## 1st data X1 = matrix(rnorm(100*120), nrow=100, ncol=120) y1 = -0.5 + X1[,1] * 0.5 + X1[,2] * 1 + rnorm(100) ## 2nd data X2 = matrix(0.8*rnorm(100*120), nrow=100, ncol=120) y2 = 0.1 + X2[,1] * 0.8 + X2[,2] * 0.8 + rnorm(100) ## loadings loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) truth1 = (0.5*1 + 1*1) - (0.8*1 + 0.8*1) truth2 = (0.5*(-0.5) + 1*(-1)) - (0.8*(-0.5) + 0.8*(-1)) truth = c(truth1, truth2) truth ## [1] -0.10 -0.05 Est = ITE(X1, y1, X2, y2, loading.mat, model=\"linear\", verbose=TRUE) ## Call: Inference for Linear Functional ======> Data 1/2  ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Call: Inference for Linear Functional ======> Data 2/2  ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.027257at step =5 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.040886at step =4 ci(Est) ##   loading      lower     upper ## 1       1 -0.9634614 0.6422924 ## 2       2 -0.5728741 0.4081881 summary(Est) ## Call:  ## Inference for Treatment Effect ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value Pr(>|z|)   ##        1   -0.03658   -0.16058     0.4096  -0.392   0.6950   ##        2   -0.14526   -0.08234     0.2503  -0.329   0.7421"},{"path":"/articles/intro.html","id":"individualized-treatment-effect-in-logistic-regression-model","dir":"Articles","previous_headings":"Examples","what":"Individualized Treatment Effect in logistic regression model","title":"intro","text":"Generate Data find truth linear functionals: Call ITE model=\"logistic\" model=\"logisitc_alter\": ci method ITE: summary method ITE:","code":"set.seed(0) ## 1st data X1 = matrix(rnorm(100*120), nrow=100, ncol=120) exp_val1 = -0.5 + X1[,1] * 0.5 + X1[,2] * 1 prob1 = exp(exp_val1) / (1 + exp(exp_val1)) y1 = rbinom(100, 1, prob1) ## 2nd data X2 = matrix(0.8*rnorm(100*120), nrow=100, ncol=120) exp_val2 = -0.5 + X2[,1] * 0.8 + X2[,2] * 0.8 prob2 = exp(exp_val2) / (1 + exp(exp_val2)) y2 = rbinom(100, 1, prob2) ## loadings loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) truth1 = (0.5*1 + 1*1) - (0.8*1 + 0.8*1) truth2 = (0.5*(-0.5) + 1*(-1)) - (0.8*(-0.5) + 0.8*(-1)) truth = c(truth1, truth2) prob.fun = function(x) exp(x)/(1+exp(x)) truth.prob1 = prob.fun(0.5*1 + 1*1) - prob.fun(0.8*1 + 0.8*1) truth.prob2 = prob.fun(0.5*(-0.5) + 1*(-1)) - prob.fun(0.8*(-0.5) + 0.8*(-1)) truth.prob = c(truth.prob1, truth.prob2)  truth; truth.prob ## [1] -0.10 -0.05 ## [1] -0.014443909 -0.008775078 Est = ITE(X1, y1, X2, y2, loading.mat, model=\"logistic\", verbose = TRUE) ## Call: Inference for Linear Functional ======> Data 1/2  ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Call: Inference for Linear Functional ======> Data 2/2  ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.040886at step =4 ## confidence interval for linear combination ci(Est) ##   loading     lower     upper ## 1       1 -1.463932 1.7455369 ## 2       2 -1.841519 0.8706693 ## confidence interval after probability transformation ci(Est, probability = TRUE) ##   loading      lower     upper ## 1       1 -0.2378692 0.2826141 ## 2       2 -0.3697559 0.1819994 summary(Est) ## Call:  ## Inference for Treatment Effect ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value Pr(>|z|)   ##        1     0.5027     0.1408     0.8188  0.1720   0.8635   ##        2    -0.6654    -0.4854     0.6919 -0.7016   0.4829"},{"path":"/articles/intro.html","id":"quadratic-functional-in-linear-regression","dir":"Articles","previous_headings":"Examples","what":"Quadratic functional in linear regression","title":"intro","text":"Generate Data find truth quadratic functionals: Call QF model=\"linear\" intial estimator given: ci method QF summary method QF","code":"set.seed(0) A1gen <- function(rho, p){   M = matrix(NA, nrow=p, ncol=p)   for(i in 1:p) for(j in 1:p) M[i,j] = rho^{abs(i-j)}   M } Cov = A1gen(0.5, 150)/2 X = MASS::mvrnorm(n=400, mu=rep(0, 150), Sigma=Cov) beta = rep(0, 150); beta[25:50] = 0.2 y = X%*%beta + rnorm(400) test.set = c(40:60) truth = as.numeric(t(beta[test.set])%*%Cov[test.set, test.set]%*%beta[test.set]) truth ## [1] 0.5800391 library(glmnet) outLas <- cv.glmnet(X, y, family = \"gaussian\", alpha = 1,                             intercept = T, standardize = T) beta.init = as.vector(coef(outLas, s = outLas$lambda.min)) tau = c(0.25, 0.5) Est = QF(X, y, G=test.set, A=NULL, model=\"linear\", beta.init=beta.init, tau=tau, verbose=TRUE) ## Computing QF...  ## The projection direction is identified at mu = 0.01394at step =6 ci(Est) ##    tau     lower     upper ## 1 0.25 0.4442377 0.7842335 ## 2 0.50 0.4197381 0.8087330 summary(Est) ## Call:  ## Inference for Quadratic Functional ##  ##   tau est.plugin est.debias Std. Error z value  Pr(>|z|)     ##  0.25     0.4958     0.6142    0.08674   7.082 1.424e-12 *** ##  0.50     0.4958     0.6142    0.09924   6.190 6.028e-10 ***"},{"path":"/articles/intro.html","id":"quadratic-functional-in-logistic-regression","dir":"Articles","previous_headings":"Examples","what":"Quadratic functional in logistic regression","title":"intro","text":"Generate Data find truth quadratic functional Call QF model=\"logistic\" model=\"logisitc\": ci method QF: summary method QF: Call QF model=\"logisitc_alter\": ci method QF: summary method QF:","code":"set.seed(0) A1gen <- function(rho, p){   M = matrix(NA, nrow=p, ncol=p)   for(i in 1:p) for(j in 1:p) M[i,j] = rho^{abs(i-j)}   M } Cov = A1gen(0.5, 150)/2 X = MASS::mvrnorm(n=400, mu=rep(0, 150), Sigma=Cov) beta = rep(0, 150); beta[25:50] = 0.2 exp_val = X%*%beta prob = exp(exp_val) / (1+exp(exp_val)) y = rbinom(400, 1, prob) test.set = c(40:60) truth = as.numeric(t(beta[test.set]%*%Cov[test.set, test.set]%*%beta[test.set])) truth ## [1] 0.5800391 tau = c(0.25, 0.5) Est = QF(X, y, G=test.set, A=NULL, model=\"logistic\", split=T, tau=tau, verbose=TRUE) ## Computing QF...  ## The projection direction is identified at mu = 0.013143at step =7 ci(Est) ##    tau lower     upper ## 1 0.25     0 0.9120369 ## 2 0.50     0 1.2316317 summary(Est) ## Call:  ## Inference for Quadratic Functional ##  ##   tau est.plugin est.debias Std. Error z value Pr(>|z|)   ##  0.25     0.2174     0.2059     0.3603  0.5714   0.5677   ##  0.50     0.2174     0.2059     0.5234  0.3934   0.6941 tau = c(0.25, 0.5) Est = QF(X, y, G=test.set, A=NULL, model=\"logistic_alter\", split=T, tau=tau, verbose=TRUE) ## Computing QF...  ## The projection direction is identified at mu = 0.013143at step =7 ci(Est) ##    tau lower    upper ## 1 0.25     0 1.120806 ## 2 0.50     0 1.563322 summary(Est) ## Call:  ## Inference for Quadratic Functional ##  ##   tau est.plugin est.debias Std. Error z value Pr(>|z|)   ##  0.25      0.191     0.2804     0.4288  0.6540   0.5131   ##  0.50      0.191     0.2804     0.6546  0.4284   0.6684"},{"path":"/articles/SIHR.html","id":"examples","dir":"Articles","previous_headings":"","what":"Examples","title":"intro","text":"basic examples show solve common high-dimensional inference problems:","code":"library(SIHR)"},{"path":"/articles/SIHR.html","id":"linear-functional-in-linear-regression-model---1","dir":"Articles","previous_headings":"Examples","what":"Linear functional in linear regression model - 1","title":"intro","text":"Generate Data find truth linear functionals: example, linear functional involve intercept term, set intercept.loading=FALSE (default). users want include intercept term, please set intercept.loading=TRUE, truth1 = -0.5 + 1.5 = 1; truth2 = -0.5 - 1.25 = -1.75 Call LF model=\"linear\": ci method LF summary method LF","code":"set.seed(0) X = matrix(rnorm(100*120), nrow=100, ncol=120) y = -0.5 + X[,1] * 0.5 + X[,2] * 1 + rnorm(100) loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) ## consider the intercept.loading=FALSE truth1 = 0.5 * 1 + 1 * 1 truth2 = 0.5 * -0.5 + 1 * -1 truth = c(truth1, truth2) truth ## [1]  1.50 -1.25 Est = LF(X, y, loading.mat, model=\"linear\", intercept=TRUE, intercept.loading=FALSE, verbose=TRUE) ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ci(Est) ##   loading     lower     upper ## 1       1  1.111919  1.722561 ## 2       2 -1.529687 -1.020350 summary(Est) ## Call:  ## Inference for Linear Functional ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     ##        1      1.158      1.417     0.1558   9.098 0.000e+00 *** ##        2     -1.015     -1.275     0.1299  -9.813 9.924e-23 ***"},{"path":"/articles/SIHR.html","id":"linear-functional-in-linear-regression-model---2","dir":"Articles","previous_headings":"Examples","what":"Linear functional in linear regression model - 2","title":"intro","text":"Sometimes, may interested multiple linear functionals, separate loading. computationally efficient, can specify argument beta.init first, program can save time compute initial estimator repeatedly. Call LF model=\"linear\": ci method LF summary method LF","code":"set.seed(1) X = matrix(rnorm(100*120), nrow=100, ncol=120) y = -0.5 + X[,1:10] %*% rep(0.5, 10) + rnorm(100) loading.mat = matrix(0, nrow=120, ncol=10) for(i in 1:ncol(loading.mat)){   loading.mat[i,i] =  1 } library(glmnet) ## Loading required package: Matrix ## Loaded glmnet 4.1-4 cvfit = cv.glmnet(X, y, family = \"gaussian\", alpha = 1, intercept = TRUE, standardize = T) beta.init = as.vector(coef(cvfit, s = cvfit$lambda.min)) Est = LF(X, y, loading.mat, model=\"linear\", intercept=TRUE, beta.init=beta.init, verbose=TRUE) ## Computing LF for loading (1/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (2/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (3/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (4/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (5/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (6/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (7/10)...  ## The projection direction is identified at mu = 0.027257at step =5 ## Computing LF for loading (8/10)...  ## The projection direction is identified at mu = 0.027257at step =5 ## Computing LF for loading (9/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (10/10)...  ## The projection direction is identified at mu = 0.040886at step =4 ci(Est) ##    loading       lower     upper ## 1        1  0.01511794 0.7789204 ## 2        2  0.17744949 1.2347802 ## 3        3  0.14589125 0.9074732 ## 4        4  0.05357240 0.7355096 ## 5        5  0.18122547 1.0292098 ## 6        6 -0.30397428 0.7048378 ## 7        7  0.33282671 0.9970891 ## 8        8  0.01564265 0.7708467 ## 9        9  0.46020627 1.0619827 ## 10      10  0.12026114 0.7637474 summary(Est) ## Call:  ## Inference for Linear Functional ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     ##        1     0.2698     0.3970     0.1949  2.0376 4.159e-02   * ##        2     0.4145     0.7061     0.2697  2.6178 8.849e-03  ** ##        3     0.4057     0.5267     0.1943  2.7109 6.711e-03  ** ##        4     0.2631     0.3945     0.1740  2.2679 2.333e-02   * ##        5     0.3773     0.6052     0.2163  2.7977 5.147e-03  ** ##        6     0.2730     0.2004     0.2574  0.7788 4.361e-01     ##        7     0.3664     0.6650     0.1695  3.9240 8.708e-05 *** ##        8     0.2911     0.3932     0.1927  2.0412 4.124e-02   * ##        9     0.5699     0.7611     0.1535  4.9577 7.133e-07 *** ##       10     0.2839     0.4420     0.1642  2.6926 7.091e-03  **"},{"path":"/articles/SIHR.html","id":"linear-functional-in-logistic-regression-model","dir":"Articles","previous_headings":"Examples","what":"Linear functional in logistic regression model","title":"intro","text":"Generate Data find truth linear functionals: Call LF model=\"logistic\" model=\"logistic_alter\": ci method LF summary method LF Call LF model=\"logistic_alter\": ci method LF summary method LF","code":"set.seed(0) X = matrix(rnorm(100*120), nrow=100, ncol=120) exp_val = -0.5 + X[,1] * 0.5 + X[,2] * 1 prob = exp(exp_val) / (1+exp(exp_val)) y = rbinom(100, 1, prob) ## loadings loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) ## consider the intercept.loading=TRUE truth1 = 0.5 * 1 + 1 * 1 truth2 = 0.5 * -0.5 + 1 * -1 truth = c(truth1, truth2) truth.prob = exp(truth) / (1 + exp(truth)) truth; truth.prob ## [1]  1.50 -1.25 ## [1] 0.8175745 0.2227001 ## model = \"logisitc\" Est = LF(X, y, loading.mat, model=\"logistic\", verbose=TRUE) ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## confidence interval for linear combination ci(Est) ##   loading      lower      upper ## 1       1  0.6393023  2.2699716 ## 2       2 -1.9644387 -0.5538893 ## confidence interval after probability transformation ci(Est, probability = TRUE) ##   loading     lower     upper ## 1       1 0.6545957 0.9063594 ## 2       2 0.1229875 0.3649625 summary(Est) ## Call:  ## Inference for Linear Functional ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     ##        1     0.8116      1.455     0.4160   3.497 0.0004709 *** ##        2    -0.8116     -1.259     0.3598  -3.499 0.0004666 *** ## model = \"logistic_alter\" Est = LF(X, y, loading.mat, model=\"logistic_alter\", verbose=TRUE) ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## confidence interval for linear combination ci(Est) ##   loading      lower      upper ## 1       1  0.6121908  2.1603820 ## 2       2 -1.8474229 -0.5201972 ## confidence interval after probability transformation ci(Est, probability = TRUE) ##   loading     lower     upper ## 1       1 0.6484404 0.8966350 ## 2       2 0.1361758 0.3728061 summary(Est) ## Call:  ## Inference for Linear Functional ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     ##        1     0.7597      1.386     0.3950   3.510 0.0004481 *** ##        2    -0.7597     -1.184     0.3386  -3.496 0.0004717 ***"},{"path":"/articles/SIHR.html","id":"individualized-treatment-effect-in-linear-regression-model","dir":"Articles","previous_headings":"Examples","what":"Individualized Treatment Effect in linear regression model","title":"intro","text":"Generate Data find truth linear functionals: Call ITE model=\"linear\": ci method ITE summary method ITE","code":"set.seed(0) ## 1st data X1 = matrix(rnorm(100*120), nrow=100, ncol=120) y1 = -0.5 + X1[,1] * 0.5 + X1[,2] * 1 + rnorm(100) ## 2nd data X2 = matrix(0.8*rnorm(100*120), nrow=100, ncol=120) y2 = 0.1 + X2[,1] * 0.8 + X2[,2] * 0.8 + rnorm(100) ## loadings loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) truth1 = (0.5*1 + 1*1) - (0.8*1 + 0.8*1) truth2 = (0.5*(-0.5) + 1*(-1)) - (0.8*(-0.5) + 0.8*(-1)) truth = c(truth1, truth2) truth ## [1] -0.10 -0.05 Est = ITE(X1, y1, X2, y2, loading.mat, model=\"linear\", verbose=TRUE) ## Call: Inference for Linear Functional ======> Data 1/2  ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Call: Inference for Linear Functional ======> Data 2/2  ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.027257at step =5 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.040886at step =4 ci(Est) ##   loading      lower     upper ## 1       1 -0.9634614 0.6422924 ## 2       2 -0.5728741 0.4081881 summary(Est) ## Call:  ## Inference for Treatment Effect ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value Pr(>|z|)   ##        1   -0.03658   -0.16058     0.4096  -0.392   0.6950   ##        2   -0.14526   -0.08234     0.2503  -0.329   0.7421"},{"path":"/articles/SIHR.html","id":"individualized-treatment-effect-in-logistic-regression-model","dir":"Articles","previous_headings":"Examples","what":"Individualized Treatment Effect in logistic regression model","title":"intro","text":"Generate Data find truth linear functionals: Call ITE model=\"logistic\" model=\"logisitc_alter\": ci method ITE: summary method ITE:","code":"set.seed(0) ## 1st data X1 = matrix(rnorm(100*120), nrow=100, ncol=120) exp_val1 = -0.5 + X1[,1] * 0.5 + X1[,2] * 1 prob1 = exp(exp_val1) / (1 + exp(exp_val1)) y1 = rbinom(100, 1, prob1) ## 2nd data X2 = matrix(0.8*rnorm(100*120), nrow=100, ncol=120) exp_val2 = -0.5 + X2[,1] * 0.8 + X2[,2] * 0.8 prob2 = exp(exp_val2) / (1 + exp(exp_val2)) y2 = rbinom(100, 1, prob2) ## loadings loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) truth1 = (0.5*1 + 1*1) - (0.8*1 + 0.8*1) truth2 = (0.5*(-0.5) + 1*(-1)) - (0.8*(-0.5) + 0.8*(-1)) truth = c(truth1, truth2) prob.fun = function(x) exp(x)/(1+exp(x)) truth.prob1 = prob.fun(0.5*1 + 1*1) - prob.fun(0.8*1 + 0.8*1) truth.prob2 = prob.fun(0.5*(-0.5) + 1*(-1)) - prob.fun(0.8*(-0.5) + 0.8*(-1)) truth.prob = c(truth.prob1, truth.prob2)  truth; truth.prob ## [1] -0.10 -0.05 ## [1] -0.014443909 -0.008775078 Est = ITE(X1, y1, X2, y2, loading.mat, model=\"logistic\", verbose = TRUE) ## Call: Inference for Linear Functional ======> Data 1/2  ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.061329at step =3 ## Call: Inference for Linear Functional ======> Data 2/2  ## Computing LF for loading (1/2)...  ## The projection direction is identified at mu = 0.040886at step =4 ## Computing LF for loading (2/2)...  ## The projection direction is identified at mu = 0.040886at step =4 ## confidence interval for linear combination ci(Est) ##   loading     lower     upper ## 1       1 -1.463932 1.7455369 ## 2       2 -1.841519 0.8706693 ## confidence interval after probability transformation ci(Est, probability = TRUE) ##   loading      lower     upper ## 1       1 -0.2378692 0.2826141 ## 2       2 -0.3697559 0.1819994 summary(Est) ## Call:  ## Inference for Treatment Effect ##  ## Estimators:  ##  loading est.plugin est.debias Std. Error z value Pr(>|z|)   ##        1     0.5027     0.1408     0.8188  0.1720   0.8635   ##        2    -0.6654    -0.4854     0.6919 -0.7016   0.4829"},{"path":"/articles/SIHR.html","id":"quadratic-functional-in-linear-regression","dir":"Articles","previous_headings":"Examples","what":"Quadratic functional in linear regression","title":"intro","text":"Generate Data find truth quadratic functionals: Call QF model=\"linear\" intial estimator given: ci method QF summary method QF","code":"set.seed(0) A1gen <- function(rho, p){   M = matrix(NA, nrow=p, ncol=p)   for(i in 1:p) for(j in 1:p) M[i,j] = rho^{abs(i-j)}   M } Cov = A1gen(0.5, 150)/2 X = MASS::mvrnorm(n=400, mu=rep(0, 150), Sigma=Cov) beta = rep(0, 150); beta[25:50] = 0.2 y = X%*%beta + rnorm(400) test.set = c(40:60) truth = as.numeric(t(beta[test.set])%*%Cov[test.set, test.set]%*%beta[test.set]) truth ## [1] 0.5800391 library(glmnet) outLas <- cv.glmnet(X, y, family = \"gaussian\", alpha = 1,                             intercept = T, standardize = T) beta.init = as.vector(coef(outLas, s = outLas$lambda.min)) tau = c(0.25, 0.5) Est = QF(X, y, G=test.set, A=NULL, model=\"linear\", beta.init=beta.init, tau=tau, verbose=TRUE) ## Computing QF...  ## The projection direction is identified at mu = 0.01394at step =6 ci(Est) ##    tau     lower     upper ## 1 0.25 0.4442377 0.7842335 ## 2 0.50 0.4197381 0.8087330 summary(Est) ## Call:  ## Inference for Quadratic Functional ##  ##   tau est.plugin est.debias Std. Error z value  Pr(>|z|)     ##  0.25     0.4958     0.6142    0.08674   7.082 1.424e-12 *** ##  0.50     0.4958     0.6142    0.09924   6.190 6.028e-10 ***"},{"path":"/articles/SIHR.html","id":"quadratic-functional-in-logistic-regression","dir":"Articles","previous_headings":"Examples","what":"Quadratic functional in logistic regression","title":"intro","text":"Generate Data find truth quadratic functional Call QF model=\"logistic\" model=\"logisitc\": ci method QF: summary method QF: Call QF model=\"logisitc_alter\": ci method QF: summary method QF:","code":"set.seed(0) A1gen <- function(rho, p){   M = matrix(NA, nrow=p, ncol=p)   for(i in 1:p) for(j in 1:p) M[i,j] = rho^{abs(i-j)}   M } Cov = A1gen(0.5, 150)/2 X = MASS::mvrnorm(n=400, mu=rep(0, 150), Sigma=Cov) beta = rep(0, 150); beta[25:50] = 0.2 exp_val = X%*%beta prob = exp(exp_val) / (1+exp(exp_val)) y = rbinom(400, 1, prob) test.set = c(40:60) truth = as.numeric(t(beta[test.set]%*%Cov[test.set, test.set]%*%beta[test.set])) truth ## [1] 0.5800391 tau = c(0.25, 0.5) Est = QF(X, y, G=test.set, A=NULL, model=\"logistic\", split=T, tau=tau, verbose=TRUE) ## Computing QF...  ## The projection direction is identified at mu = 0.013143at step =7 ci(Est) ##    tau lower     upper ## 1 0.25     0 0.9120369 ## 2 0.50     0 1.2316317 summary(Est) ## Call:  ## Inference for Quadratic Functional ##  ##   tau est.plugin est.debias Std. Error z value Pr(>|z|)   ##  0.25     0.2174     0.2059     0.3603  0.5714   0.5677   ##  0.50     0.2174     0.2059     0.5234  0.3934   0.6941 tau = c(0.25, 0.5) Est = QF(X, y, G=test.set, A=NULL, model=\"logistic_alter\", split=T, tau=tau, verbose=TRUE) ## Computing QF...  ## The projection direction is identified at mu = 0.013143at step =7 ci(Est) ##    tau lower    upper ## 1 0.25     0 1.120806 ## 2 0.50     0 1.563322 summary(Est) ## Call:  ## Inference for Quadratic Functional ##  ##   tau est.plugin est.debias Std. Error z value Pr(>|z|)   ##  0.25      0.191     0.2804     0.4288  0.6540   0.5131   ##  0.50      0.191     0.2804     0.6546  0.4284   0.6684"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Zijian Guo. Maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Rakshit P, Wang Z, Cai T, Guo Z (2022). SIHR: Statistical Inference High Dimensional Regression. R package version 1.1.0, https://github.com/prabrishar1/SIHR.","code":"@Manual{,   title = {SIHR: Statistical Inference in High Dimensional Regression},   author = {Prabrisha Rakshit and Zhenyu Wang and Tony Cai and Zijian Guo},   year = {2022},   note = {R package version 1.1.0},   url = {https://github.com/prabrishar1/SIHR}, }"},{"path":"/index.html","id":"sihr","dir":"","previous_headings":"","what":"Statistical Inference in High Dimensional Regression","title":"Statistical Inference in High Dimensional Regression","text":"goal SIHR provide inference procedures high-dimensional setting (1) linear functionals generalized linear regression, (2) individual treatment effects generalized linear regression (ITE), (3) quadratic functionals generalized linear regression (QF). Currently, support different generalized linear regression, specifying argument model “linear”, “logisitc”, “logistic_alter” “probit”.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Statistical Inference in High Dimensional Regression","text":"can install development version GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"prabrishar1/SIHR\")"},{"path":"/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Statistical Inference in High Dimensional Regression","text":"basic examples show solve common high-dimensional inference problems:","code":"library(SIHR)"},{"path":"/index.html","id":"linear-functional-in-linear-regression-model---1","dir":"","previous_headings":"Examples","what":"Linear functional in linear regression model - 1","title":"Statistical Inference in High Dimensional Regression","text":"Generate Data find truth linear functionals: example, linear functional involve intercept term, set intercept.loading=FALSE (default). users want include intercept term, please set intercept.loading=TRUE, truth1 = -0.5 + 1.5 = 1; truth2 = -0.5 - 1.25 = -1.75 Call LF model=\"linear\": ci method LF summary method LF","code":"set.seed(0) X = matrix(rnorm(100*120), nrow=100, ncol=120) y = -0.5 + X[,1] * 0.5 + X[,2] * 1 + rnorm(100) loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) ## consider the intercept.loading=FALSE truth1 = 0.5 * 1 + 1 * 1 truth2 = 0.5 * -0.5 + 1 * -1 truth = c(truth1, truth2) truth #> [1]  1.50 -1.25 Est = LF(X, y, loading.mat, model=\"linear\", intercept=TRUE, intercept.loading=FALSE, verbose=TRUE) #> Computing LF for loading (1/2)...  #> The projection direction is identified at mu = 0.061329at step =3 #> Computing LF for loading (2/2)...  #> The projection direction is identified at mu = 0.061329at step =3 ci(Est) #>   loading     lower     upper #> 1       1  1.111919  1.722561 #> 2       2 -1.529687 -1.020350 summary(Est) #> Call:  #> Inference for Linear Functional #>  #> Estimators:  #>  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     #>        1      1.158      1.417     0.1558   9.098 0.000e+00 *** #>        2     -1.015     -1.275     0.1299  -9.813 9.924e-23 ***"},{"path":"/index.html","id":"linear-functional-in-linear-regression-model---2","dir":"","previous_headings":"Examples","what":"Linear functional in linear regression model - 2","title":"Statistical Inference in High Dimensional Regression","text":"Sometimes, may interested multiple linear functionals, separate loading. computationally efficient, can specify argument beta.init first, program can save time compute initial estimator repeatedly. Call LF model=\"linear\": ci method LF summary method LF","code":"set.seed(1) X = matrix(rnorm(100*120), nrow=100, ncol=120) y = -0.5 + X[,1:10] %*% rep(0.5, 10) + rnorm(100) loading.mat = matrix(0, nrow=120, ncol=10) for(i in 1:ncol(loading.mat)){   loading.mat[i,i] =  1 } library(glmnet) #> Loading required package: Matrix #> Loaded glmnet 4.1-4 cvfit = cv.glmnet(X, y, family = \"gaussian\", alpha = 1, intercept = TRUE, standardize = T) beta.init = as.vector(coef(cvfit, s = cvfit$lambda.min)) Est = LF(X, y, loading.mat, model=\"linear\", intercept=TRUE, beta.init=beta.init, verbose=TRUE) #> Computing LF for loading (1/10)...  #> The projection direction is identified at mu = 0.040886at step =4 #> Computing LF for loading (2/10)...  #> The projection direction is identified at mu = 0.040886at step =4 #> Computing LF for loading (3/10)...  #> The projection direction is identified at mu = 0.040886at step =4 #> Computing LF for loading (4/10)...  #> The projection direction is identified at mu = 0.040886at step =4 #> Computing LF for loading (5/10)...  #> The projection direction is identified at mu = 0.040886at step =4 #> Computing LF for loading (6/10)...  #> The projection direction is identified at mu = 0.040886at step =4 #> Computing LF for loading (7/10)...  #> The projection direction is identified at mu = 0.027257at step =5 #> Computing LF for loading (8/10)...  #> The projection direction is identified at mu = 0.027257at step =5 #> Computing LF for loading (9/10)...  #> The projection direction is identified at mu = 0.040886at step =4 #> Computing LF for loading (10/10)...  #> The projection direction is identified at mu = 0.040886at step =4 ci(Est) #>    loading       lower     upper #> 1        1  0.01511794 0.7789204 #> 2        2  0.17744949 1.2347802 #> 3        3  0.14589125 0.9074732 #> 4        4  0.05357240 0.7355096 #> 5        5  0.18122547 1.0292098 #> 6        6 -0.30397428 0.7048378 #> 7        7  0.33282671 0.9970891 #> 8        8  0.01564265 0.7708467 #> 9        9  0.46020627 1.0619827 #> 10      10  0.12026114 0.7637474 summary(Est) #> Call:  #> Inference for Linear Functional #>  #> Estimators:  #>  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     #>        1     0.2698     0.3970     0.1949  2.0376 4.159e-02   * #>        2     0.4145     0.7061     0.2697  2.6178 8.849e-03  ** #>        3     0.4057     0.5267     0.1943  2.7109 6.711e-03  ** #>        4     0.2631     0.3945     0.1740  2.2679 2.333e-02   * #>        5     0.3773     0.6052     0.2163  2.7977 5.147e-03  ** #>        6     0.2730     0.2004     0.2574  0.7788 4.361e-01     #>        7     0.3664     0.6650     0.1695  3.9240 8.708e-05 *** #>        8     0.2911     0.3932     0.1927  2.0412 4.124e-02   * #>        9     0.5699     0.7611     0.1535  4.9577 7.133e-07 *** #>       10     0.2839     0.4420     0.1642  2.6926 7.091e-03  **"},{"path":"/index.html","id":"linear-functional-in-logistic-regression-model","dir":"","previous_headings":"Examples","what":"Linear functional in logistic regression model","title":"Statistical Inference in High Dimensional Regression","text":"Generate Data find truth linear functionals: Call LF model=\"logistic\" model=\"logistic_alter\": ci method LF summary method LF Call LF model=\"logistic_alter\": ci method LF summary method LF","code":"set.seed(0) X = matrix(rnorm(100*120), nrow=100, ncol=120) exp_val = -0.5 + X[,1] * 0.5 + X[,2] * 1 prob = exp(exp_val) / (1+exp(exp_val)) y = rbinom(100, 1, prob) ## loadings loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) ## consider the intercept.loading=TRUE truth1 = 0.5 * 1 + 1 * 1 truth2 = 0.5 * -0.5 + 1 * -1 truth = c(truth1, truth2) truth.prob = exp(truth) / (1 + exp(truth)) truth; truth.prob #> [1]  1.50 -1.25 #> [1] 0.8175745 0.2227001 ## model = \"logisitc\" Est = LF(X, y, loading.mat, model=\"logistic\", verbose=TRUE) #> Computing LF for loading (1/2)...  #> The projection direction is identified at mu = 0.061329at step =3 #> Computing LF for loading (2/2)...  #> The projection direction is identified at mu = 0.061329at step =3 ## confidence interval for linear combination ci(Est) #>   loading      lower      upper #> 1       1  0.6393023  2.2699716 #> 2       2 -1.9644387 -0.5538893 ## confidence interval after probability transformation ci(Est, probability = TRUE) #>   loading     lower     upper #> 1       1 0.6545957 0.9063594 #> 2       2 0.1229875 0.3649625 summary(Est) #> Call:  #> Inference for Linear Functional #>  #> Estimators:  #>  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     #>        1     0.8116      1.455     0.4160   3.497 0.0004709 *** #>        2    -0.8116     -1.259     0.3598  -3.499 0.0004666 *** ## model = \"logistic_alter\" Est = LF(X, y, loading.mat, model=\"logistic_alter\", verbose=TRUE) #> Computing LF for loading (1/2)...  #> The projection direction is identified at mu = 0.061329at step =3 #> Computing LF for loading (2/2)...  #> The projection direction is identified at mu = 0.061329at step =3 ## confidence interval for linear combination ci(Est) #>   loading      lower      upper #> 1       1  0.6121908  2.1603820 #> 2       2 -1.8474229 -0.5201972 ## confidence interval after probability transformation ci(Est, probability = TRUE) #>   loading     lower     upper #> 1       1 0.6484404 0.8966350 #> 2       2 0.1361758 0.3728061 summary(Est) #> Call:  #> Inference for Linear Functional #>  #> Estimators:  #>  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     #>        1     0.7597      1.386     0.3950   3.510 0.0004481 *** #>        2    -0.7597     -1.184     0.3386  -3.496 0.0004717 ***"},{"path":"/index.html","id":"individualized-treatment-effect-in-linear-regression-model","dir":"","previous_headings":"Examples","what":"Individualized Treatment Effect in linear regression model","title":"Statistical Inference in High Dimensional Regression","text":"Generate Data find truth linear functionals: Call ITE model=\"linear\": ci method ITE summary method ITE","code":"set.seed(0) ## 1st data X1 = matrix(rnorm(100*120), nrow=100, ncol=120) y1 = -0.5 + X1[,1] * 0.5 + X1[,2] * 1 + rnorm(100) ## 2nd data X2 = matrix(0.8*rnorm(100*120), nrow=100, ncol=120) y2 = 0.1 + X2[,1] * 0.8 + X2[,2] * 0.8 + rnorm(100) ## loadings loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) truth1 = (0.5*1 + 1*1) - (0.8*1 + 0.8*1) truth2 = (0.5*(-0.5) + 1*(-1)) - (0.8*(-0.5) + 0.8*(-1)) truth = c(truth1, truth2) truth #> [1] -0.10 -0.05 Est = ITE(X1, y1, X2, y2, loading.mat, model=\"linear\", verbose=TRUE) #> Call: Inference for Linear Functional ======> Data 1/2  #> Computing LF for loading (1/2)...  #> The projection direction is identified at mu = 0.061329at step =3 #> Computing LF for loading (2/2)...  #> The projection direction is identified at mu = 0.061329at step =3 #> Call: Inference for Linear Functional ======> Data 2/2  #> Computing LF for loading (1/2)...  #> The projection direction is identified at mu = 0.027257at step =5 #> Computing LF for loading (2/2)...  #> The projection direction is identified at mu = 0.040886at step =4 ci(Est) #>   loading      lower     upper #> 1       1 -0.9634614 0.6422924 #> 2       2 -0.5728741 0.4081881 summary(Est) #> Call:  #> Inference for Treatment Effect #>  #> Estimators:  #>  loading est.plugin est.debias Std. Error z value Pr(>|z|)   #>        1   -0.03658   -0.16058     0.4096  -0.392   0.6950   #>        2   -0.14526   -0.08234     0.2503  -0.329   0.7421"},{"path":"/index.html","id":"individualized-treatment-effect-in-logistic-regression-model","dir":"","previous_headings":"Examples","what":"Individualized Treatment Effect in logistic regression model","title":"Statistical Inference in High Dimensional Regression","text":"Generate Data find truth linear functionals: Call ITE model=\"logistic\" model=\"logisitc_alter\": ci method ITE: summary method ITE:","code":"set.seed(0) ## 1st data X1 = matrix(rnorm(100*120), nrow=100, ncol=120) exp_val1 = -0.5 + X1[,1] * 0.5 + X1[,2] * 1 prob1 = exp(exp_val1) / (1 + exp(exp_val1)) y1 = rbinom(100, 1, prob1) ## 2nd data X2 = matrix(0.8*rnorm(100*120), nrow=100, ncol=120) exp_val2 = -0.5 + X2[,1] * 0.8 + X2[,2] * 0.8 prob2 = exp(exp_val2) / (1 + exp(exp_val2)) y2 = rbinom(100, 1, prob2) ## loadings loading1 = c(1, 1, rep(0, 118)) loading2 = c(-0.5, -1, rep(0, 118)) loading.mat = cbind(loading1, loading2) truth1 = (0.5*1 + 1*1) - (0.8*1 + 0.8*1) truth2 = (0.5*(-0.5) + 1*(-1)) - (0.8*(-0.5) + 0.8*(-1)) truth = c(truth1, truth2) prob.fun = function(x) exp(x)/(1+exp(x)) truth.prob1 = prob.fun(0.5*1 + 1*1) - prob.fun(0.8*1 + 0.8*1) truth.prob2 = prob.fun(0.5*(-0.5) + 1*(-1)) - prob.fun(0.8*(-0.5) + 0.8*(-1)) truth.prob = c(truth.prob1, truth.prob2)  truth; truth.prob #> [1] -0.10 -0.05 #> [1] -0.014443909 -0.008775078 Est = ITE(X1, y1, X2, y2, loading.mat, model=\"logistic\", verbose = TRUE) #> Call: Inference for Linear Functional ======> Data 1/2  #> Computing LF for loading (1/2)...  #> The projection direction is identified at mu = 0.061329at step =3 #> Computing LF for loading (2/2)...  #> The projection direction is identified at mu = 0.061329at step =3 #> Call: Inference for Linear Functional ======> Data 2/2  #> Computing LF for loading (1/2)...  #> The projection direction is identified at mu = 0.040886at step =4 #> Computing LF for loading (2/2)...  #> The projection direction is identified at mu = 0.040886at step =4 ## confidence interval for linear combination ci(Est) #>   loading     lower     upper #> 1       1 -1.463932 1.7455369 #> 2       2 -1.841519 0.8706693 ## confidence interval after probability transformation ci(Est, probability = TRUE) #>   loading      lower     upper #> 1       1 -0.2378692 0.2826141 #> 2       2 -0.3697559 0.1819994 summary(Est) #> Call:  #> Inference for Treatment Effect #>  #> Estimators:  #>  loading est.plugin est.debias Std. Error z value Pr(>|z|)   #>        1     0.5027     0.1408     0.8188  0.1720   0.8635   #>        2    -0.6654    -0.4854     0.6919 -0.7016   0.4829"},{"path":"/index.html","id":"quadratic-functional-in-linear-regression","dir":"","previous_headings":"Examples","what":"Quadratic functional in linear regression","title":"Statistical Inference in High Dimensional Regression","text":"Generate Data find truth quadratic functionals: Call QF model=\"linear\" intial estimator given: ci method QF summary method QF","code":"set.seed(0) A1gen <- function(rho, p){   M = matrix(NA, nrow=p, ncol=p)   for(i in 1:p) for(j in 1:p) M[i,j] = rho^{abs(i-j)}   M } Cov = A1gen(0.5, 150)/2 X = MASS::mvrnorm(n=400, mu=rep(0, 150), Sigma=Cov) beta = rep(0, 150); beta[25:50] = 0.2 y = X%*%beta + rnorm(400) test.set = c(40:60) truth = as.numeric(t(beta[test.set])%*%Cov[test.set, test.set]%*%beta[test.set]) truth #> [1] 0.5800391 library(glmnet) outLas <- cv.glmnet(X, y, family = \"gaussian\", alpha = 1,                             intercept = T, standardize = T) beta.init = as.vector(coef(outLas, s = outLas$lambda.min)) tau = c(0.25, 0.5) Est = QF(X, y, G=test.set, A=NULL, model=\"linear\", beta.init=beta.init, tau=tau, verbose=TRUE) #> Computing QF...  #> The projection direction is identified at mu = 0.01394at step =6 ci(Est) #>    tau     lower     upper #> 1 0.25 0.4442377 0.7842335 #> 2 0.50 0.4197381 0.8087330 summary(Est) #> Call:  #> Inference for Quadratic Functional #>  #>   tau est.plugin est.debias Std. Error z value  Pr(>|z|)     #>  0.25     0.4958     0.6142    0.08674   7.082 1.424e-12 *** #>  0.50     0.4958     0.6142    0.09924   6.190 6.028e-10 ***"},{"path":"/index.html","id":"quadratic-functional-in-logistic-regression","dir":"","previous_headings":"Examples","what":"Quadratic functional in logistic regression","title":"Statistical Inference in High Dimensional Regression","text":"Generate Data find truth quadratic functional Call QF model=\"logistic\" model=\"logisitc\": ci method QF: summary method QF: Call QF model=\"logisitc_alter\": ci method QF: summary method QF:","code":"set.seed(0) A1gen <- function(rho, p){   M = matrix(NA, nrow=p, ncol=p)   for(i in 1:p) for(j in 1:p) M[i,j] = rho^{abs(i-j)}   M } Cov = A1gen(0.5, 150)/2 X = MASS::mvrnorm(n=400, mu=rep(0, 150), Sigma=Cov) beta = rep(0, 150); beta[25:50] = 0.2 exp_val = X%*%beta prob = exp(exp_val) / (1+exp(exp_val)) y = rbinom(400, 1, prob) test.set = c(40:60) truth = as.numeric(t(beta[test.set]%*%Cov[test.set, test.set]%*%beta[test.set])) truth #> [1] 0.5800391 tau = c(0.25, 0.5) Est = QF(X, y, G=test.set, A=NULL, model=\"logistic\", split=T, tau=tau, verbose=TRUE) #> Computing QF...  #> The projection direction is identified at mu = 0.013143at step =7 ci(Est) #>    tau lower     upper #> 1 0.25     0 0.9120369 #> 2 0.50     0 1.2316317 summary(Est) #> Call:  #> Inference for Quadratic Functional #>  #>   tau est.plugin est.debias Std. Error z value Pr(>|z|)   #>  0.25     0.2174     0.2059     0.3603  0.5714   0.5677   #>  0.50     0.2174     0.2059     0.5234  0.3934   0.6941 tau = c(0.25, 0.5) Est = QF(X, y, G=test.set, A=NULL, model=\"logistic_alter\", split=T, tau=tau, verbose=TRUE) #> Computing QF...  #> The projection direction is identified at mu = 0.013143at step =7 ci(Est) #>    tau lower    upper #> 1 0.25     0 1.120806 #> 2 0.50     0 1.563322 summary(Est) #> Call:  #> Inference for Quadratic Functional #>  #>   tau est.plugin est.debias Std. Error z value Pr(>|z|)   #>  0.25      0.191     0.2804     0.4288  0.6540   0.5131   #>  0.50      0.191     0.2804     0.6546  0.4284   0.6684"},{"path":"/reference/ci.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals for Bias-corrected Estimators — ci","title":"Confidence Intervals for Bias-corrected Estimators — ci","text":"generic function","code":""},{"path":"/reference/ci.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals for Bias-corrected Estimators — ci","text":"","code":"ci(   object,   probability = FALSE,   alpha = 0.05,   alternative = c(\"two.sided\", \"less\", \"greater\"),   ... )"},{"path":"/reference/ci.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals for Bias-corrected Estimators — ci","text":"object object class probability Whether returns CI probability transformation (default=FALSE) alpha Level significance construct confidence interval (default=0.05) alternative Indicates alternative hypothesis construct confidence interval must one \"two.sided\" (default), \"less\", \"greater\". ... arguments pass ","code":""},{"path":"/reference/ci.ITE.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals for Bias-corrected ITE Estimators — ci.ITE","title":"Confidence Intervals for Bias-corrected ITE Estimators — ci.ITE","text":"Computes confidence intervals bias-corrected estimators; row corresponds loading.","code":""},{"path":"/reference/ci.ITE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals for Bias-corrected ITE Estimators — ci.ITE","text":"","code":"# S3 method for ITE ci(   object,   probability = FALSE,   alpha = 0.05,   alternative = c(\"two.sided\", \"less\", \"greater\"),   ... )"},{"path":"/reference/ci.ITE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals for Bias-corrected ITE Estimators — ci.ITE","text":"object object class `ITE`, result call `ITE` probability Whether returns CI probability transformation (default=FALSE) alpha Level significance construct confidence interval (default=0.05) alternative Indicates alternative hypothesis construct confidence interval must one \"two.sided\" (default), \"less\", \"greater\". ... arguments pass ","code":""},{"path":"/reference/ci.ITE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence Intervals for Bias-corrected ITE Estimators — ci.ITE","text":"matrix columns giving lower upper confidence limits bias-corrected estimators.","code":""},{"path":"/reference/ci.ITE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence Intervals for Bias-corrected ITE Estimators — ci.ITE","text":"","code":"if (FALSE) { ##-- Continuing the ITE(.) example: out = ci(Est) out }"},{"path":"/reference/ci.LF.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals for Bias-corrected LF Estimators — ci.LF","title":"Confidence Intervals for Bias-corrected LF Estimators — ci.LF","text":"Computes confidence intervals bias-corrected estimators; row corresponds loading.","code":""},{"path":"/reference/ci.LF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals for Bias-corrected LF Estimators — ci.LF","text":"","code":"# S3 method for LF ci(   object,   probability = FALSE,   alpha = 0.05,   alternative = c(\"two.sided\", \"less\", \"greater\"),   ... )"},{"path":"/reference/ci.LF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals for Bias-corrected LF Estimators — ci.LF","text":"object object class `LF`, result call `LF` probability Whether returns CI probability transformation (default=FALSE) alpha Level significance construct confidence interval (default=0.05) alternative Indicates alternative hypothesis construct confidence interval must one \"two.sided\" (default), \"less\", \"greater\". ... arguments pass ","code":""},{"path":"/reference/ci.LF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence Intervals for Bias-corrected LF Estimators — ci.LF","text":"matrix columns giving lower upper confidence limits bias-corrected estimators.","code":""},{"path":"/reference/ci.LF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence Intervals for Bias-corrected LF Estimators — ci.LF","text":"","code":"if (FALSE) { ##-- Continuing the LF(.) example: out = ci(Est) out }"},{"path":"/reference/ci.QF.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals for Bias-corrected QF Estimators — ci.QF","title":"Confidence Intervals for Bias-corrected QF Estimators — ci.QF","text":"Computes confidence intervals bias-corrected estimators; row corresponds tau value.","code":""},{"path":"/reference/ci.QF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals for Bias-corrected QF Estimators — ci.QF","text":"","code":"# S3 method for QF ci(   object,   probability = FALSE,   alpha = 0.05,   alternative = c(\"two.sided\", \"less\", \"greater\"),   ... )"},{"path":"/reference/ci.QF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals for Bias-corrected QF Estimators — ci.QF","text":"object object class `QF`, result call `QF` probability Whether returns CI probability transformation (default=FALSE) alpha Level significance construct confidence interval (default=0.05) alternative Indicates alternative hypothesis construct confidence interval must one \"two.sided\" (default), \"less\", \"greater\". ... arguments pass ","code":""},{"path":"/reference/ci.QF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence Intervals for Bias-corrected QF Estimators — ci.QF","text":"matrix columns giving lower upper confidence limits bias-corrected estimators, rows corresponding different tau.","code":""},{"path":"/reference/ci.QF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence Intervals for Bias-corrected QF Estimators — ci.QF","text":"","code":"if (FALSE) { ##-- Continuing the QF(.) example: out = ci(Est) out }"},{"path":"/reference/ITE.html","id":null,"dir":"Reference","previous_headings":"","what":"Inference for difference of linear combinations of the regression vectors in\r\nhigh dimensional generalized linear regressions — ITE","title":"Inference for difference of linear combinations of the regression vectors in\r\nhigh dimensional generalized linear regressions — ITE","text":"Computes bias-corrected estimator difference   linearcombinations regression vectors high dimensional   generalized linear regressions corresponding standard error.","code":""},{"path":"/reference/ITE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inference for difference of linear combinations of the regression vectors in\r\nhigh dimensional generalized linear regressions — ITE","text":"","code":"ITE(   X1,   y1,   X2,   y2,   loading.mat,   model = c(\"linear\", \"logistic\", \"logistic_alter\"),   intercept = TRUE,   intercept.loading = FALSE,   beta.init1 = NULL,   beta.init2 = NULL,   lambda = NULL,   mu = NULL,   prob.filter = 0.05,   rescale = 1.1,   alpha = 0.05,   verbose = FALSE )"},{"path":"/reference/ITE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inference for difference of linear combinations of the regression vectors in\r\nhigh dimensional generalized linear regressions — ITE","text":"X1 Design matrix first sample, dimension \\(n_1\\) x \\(p\\) y1 Outcome vector first sample, length \\(n_1\\) X2 Design matrix second sample, dimension \\(n_2\\) x \\(p\\) y2 Outcome vector second sample, length \\(n_1\\) loading.mat Loading matrix, nrow=\\(p\\), column corresponds loading interest model high dimensional regression model, either \"linear\" \"logistic\" \"logistic_alter\" intercept intercept(s) fitted initial estimators (default = TRUE) intercept.loading intercept term included loading (default = FALSE) beta.init1 initial estimator regression vector 1st data (default = NULL) beta.init2 initial estimator regression vector 2nd data (default = NULL) lambda tuning parameter fitting initial model. NULL, picked cross-validation. (default = NULL) mu dual tuning parameter used construction projection direction. NULL searched automatically. (default = NULL) prob.filter threshold estimated probabilities filtering observations logistic regression. (default = 0.05) rescale factor enlarge standard error account finite sample bias. (default = 1.1) alpha Level significance construct two-sided confidence interval (default = 0.05) verbose intermediate message(s) printed (default = FALSE)","code":""},{"path":"/reference/ITE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inference for difference of linear combinations of the regression vectors in\r\nhigh dimensional generalized linear regressions — ITE","text":"list consists plugin estimators, debiased estimators, confidence intervals. logistic regression, also returns items probability transformation. est.plugin.vec vector plugin(biased) estimators linear combination regression coefficients, length ncol(loading.mat); corresponding different column loading.mat est.debias.vec vector bias-corrected estimators linear combination regression coefficients, length ncol(loading.mat); corresponding different column loading.mat se.vec vector standard errors bias-corrected estimators, length ncol(loading.mat); corresponding different column loading.mat ci.mat matrix two.sided confidence interval linear combination, dimension ncol(loading.mat) x \\(2\\); row corresponding different column loading.mat prob.debias.vec vector bias-corrected estimators probability transformation, length ncol(loading.mat); corresponding different column loading.mat. prob.se.vec vector standard errors bias-corrected estimators probability transformation, length ncol(loading.mat); corresponding different column loading.mat. prob.ci.mat matrix two.sided confidence interval bias-corrected estimators probability transformation, dimension ncol(loading.mat) x \\(2\\); row corresponding different column loading.mat.","code":""},{"path":"/reference/ITE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inference for difference of linear combinations of the regression vectors in\r\nhigh dimensional generalized linear regressions — ITE","text":"","code":"X1 = matrix(rnorm(100*5), nrow=100, ncol=5) y1 = -0.5 + X1[,1] * 0.5 + X1[,2] * 1 + rnorm(100) X2 = matrix(rnorm(90*5), nrow=90, ncol=5) y2 = -0.4 + X2[,1] * 0.48 + X2[,2] * 1.1 + rnorm(90) loading1 = c(1, 1, rep(0,3)) loading2 = c(-0.5, -1, rep(0,3)) loading.mat = cbind(loading1, loading2) Est = ITE(X1, y1, X2, y2, loading.mat, model=\"linear\")  ## compute confidence intervals ci(Est, alpha=0.05, alternative=\"two.sided\") #>   loading      lower     upper #> 1       1 -0.5885783 0.2574425 #> 2       2 -0.1904878 0.4602896  ## summary statistics summary(Est) #> Call:  #> Inference for Treatment Effect #>  #> Estimators:  #>  loading est.plugin est.debias Std. Error z value Pr(>|z|)   #>        1    -0.2869    -0.1656     0.2158 -0.7671   0.4430   #>        2     0.2280     0.1349     0.1660  0.8126   0.4165"},{"path":"/reference/LF.html","id":null,"dir":"Reference","previous_headings":"","what":"Inference for linear combination of the regression vector in high dimensional\r\ngeneralized linear regression — LF","title":"Inference for linear combination of the regression vector in high dimensional\r\ngeneralized linear regression — LF","text":"Inference linear combination regression vector high dimensional generalized linear regression","code":""},{"path":"/reference/LF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inference for linear combination of the regression vector in high dimensional\r\ngeneralized linear regression — LF","text":"","code":"LF(   X,   y,   loading.mat,   model = c(\"linear\", \"logistic\", \"logistic_alter\"),   intercept = TRUE,   intercept.loading = FALSE,   beta.init = NULL,   lambda = NULL,   mu = NULL,   prob.filter = 0.05,   rescale = 1.1,   alpha = 0.05,   verbose = FALSE )"},{"path":"/reference/LF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inference for linear combination of the regression vector in high dimensional\r\ngeneralized linear regression — LF","text":"X Design matrix, dimension \\(n\\) x \\(p\\) y Outcome vector, length \\(n\\) loading.mat Loading matrix, nrow=\\(p\\), column corresponds loading interest model high dimensional regression model, either \"linear\" \"logistic\" \"logistic_alter\" intercept intercept fitted initial estimator (default = TRUE) intercept.loading intercept term included loading (default = FALSE) beta.init initial estimator regression vector (default = NULL) lambda tuning parameter fitting initial model. NULL, picked cross-validation. (default = NULL) mu dual tuning parameter used construction projection direction. NULL searched automatically. (default = NULL) prob.filter threshold estimated probabilities filtering observations logistic regression. (default = 0.05) rescale factor enlarge standard error account finite sample bias. (default = 1.1) alpha Level significance construct two-sided confidence interval (default = 0.05) verbose intermediate message(s) printed, projection direction returned. (default = FALSE)","code":""},{"path":"/reference/LF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inference for linear combination of the regression vector in high dimensional\r\ngeneralized linear regression — LF","text":"est.plugin.vec vector plugin(biased) estimators linear combination regression coefficients, length ncol(loading.mat); corresponding loading interest est.debias.vec vector bias-corrected estimators linear combination regression coefficients, length ncol(loading.mat); corresponding loading interest se.vec vector standard errors bias-corrected estimators, length ncol(loading.mat); corresponding loading interest ci.mat matrix two.sided confidence interval linear combination, dimension ncol(loading.mat) x \\(2\\); row corresponding loading interest proj.mat matrix projection directions; column corresponding loading interest. returned verbose set TRUE","code":""},{"path":"/reference/LF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inference for linear combination of the regression vector in high dimensional\r\ngeneralized linear regression — LF","text":"","code":"X = matrix(rnorm(100*5), nrow=100, ncol=5) y = -0.5 + X[,1] * 0.5 + X[,2] * 1 + rnorm(100) loading1 = c(1, 1, rep(0, 3)) loading2 = c(-0.5, -1, rep(0, 3)) loading.mat = cbind(loading1, loading2) Est = LF(X, y, loading.mat, model=\"linear\")  ## compute confidence intervals ci(Est, alpha=0.05, alternative=\"two.sided\") #>   loading     lower     upper #> 1       1  1.186834  1.721444 #> 2       2 -1.429689 -1.002374  ## summary statistics summary(Est) #> Call:  #> Inference for Linear Functional #>  #> Estimators:  #>  loading est.plugin est.debias Std. Error z value  Pr(>|z|)     #>        1      1.448      1.454     0.1364   10.66 0.000e+00 *** #>        2     -1.211     -1.216     0.1090  -11.16 6.758e-29 ***"},{"path":"/reference/print.summary.ITE.html","id":null,"dir":"Reference","previous_headings":"","what":"Printing Summarizing ITE — print.summary.ITE","title":"Printing Summarizing ITE — print.summary.ITE","text":"`print` method class `summary.ITE`","code":""},{"path":"/reference/print.summary.ITE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Printing Summarizing ITE — print.summary.ITE","text":"","code":"# S3 method for summary.ITE print(x, digits = max(3, getOption(\"digits\") - 3), ...)"},{"path":"/reference/print.summary.ITE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Printing Summarizing ITE — print.summary.ITE","text":"x object class `summary.ITE`, result call `summary.ITE` digits number digits use printing ... arguments pass ","code":""},{"path":"/reference/print.summary.ITE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Printing Summarizing ITE — print.summary.ITE","text":"","code":"if (FALSE) { #' ##-- Continuing the ITE(.) example: summary(Est) }"},{"path":"/reference/print.summary.LF.html","id":null,"dir":"Reference","previous_headings":"","what":"Printing Summarizing LF — print.summary.LF","title":"Printing Summarizing LF — print.summary.LF","text":"`print` method class `summary.LF`","code":""},{"path":"/reference/print.summary.LF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Printing Summarizing LF — print.summary.LF","text":"","code":"# S3 method for summary.LF print(x, digits = max(3, getOption(\"digits\") - 3), ...)"},{"path":"/reference/print.summary.LF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Printing Summarizing LF — print.summary.LF","text":"x object class `summary.LF`, result call `summary.LF` digits number digits use printing ... arguments pass ","code":""},{"path":"/reference/print.summary.LF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Printing Summarizing LF — print.summary.LF","text":"","code":"if (FALSE) { #' ##-- Continuing the LF(.) example: summary(Est) }"},{"path":"/reference/print.summary.QF.html","id":null,"dir":"Reference","previous_headings":"","what":"Printing ummarizing QF — print.summary.QF","title":"Printing ummarizing QF — print.summary.QF","text":"`print` method class `summary.QF`","code":""},{"path":"/reference/print.summary.QF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Printing ummarizing QF — print.summary.QF","text":"","code":"# S3 method for summary.QF print(x, digits = max(3, getOption(\"digits\") - 3), ...)"},{"path":"/reference/print.summary.QF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Printing ummarizing QF — print.summary.QF","text":"x object class `summary.QF`, result call `summary.QF` digits number digits use printing ... arguments pass ","code":""},{"path":"/reference/print.summary.QF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Printing ummarizing QF — print.summary.QF","text":"","code":"if (FALSE) { #' ##-- Continuing the QF(.) example: summary(Est) }"},{"path":"/reference/QF.html","id":null,"dir":"Reference","previous_headings":"","what":"Inference for quadratic forms of the regression vector in high dimensional\r\ngeneralized linear regressions — QF","title":"Inference for quadratic forms of the regression vector in high dimensional\r\ngeneralized linear regressions — QF","text":"Inference quadratic forms regression vector high dimensional generalized linear regressions","code":""},{"path":"/reference/QF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inference for quadratic forms of the regression vector in high dimensional\r\ngeneralized linear regressions — QF","text":"","code":"QF(   X,   y,   G,   A = NULL,   model = c(\"linear\", \"logistic\", \"logistic_alter\"),   intercept = TRUE,   beta.init = NULL,   split = TRUE,   lambda = NULL,   mu = NULL,   prob.filter = 0.05,   rescale = 1.1,   tau = c(0.25, 0.5),   alpha = 0.05,   verbose = FALSE )"},{"path":"/reference/QF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inference for quadratic forms of the regression vector in high dimensional\r\ngeneralized linear regressions — QF","text":"X Design matrix, dimension \\(n\\) x \\(p\\) y Outcome vector, length \\(n\\) G set indices, G quadratic form matrix quadratic form, dimension \\(|G|\\times\\)\\(|G|\\). NULL set \\(|G|\\times\\)\\(|G|\\) submatrix population covariance matrix corresponding index set G (default = NULL) model high dimensional regression model, either \"linear\" \"logistic\" \"logistic_alter\" intercept intercept fitted initial estimator (default = TRUE) beta.init initial estimator regression vector (default = NULL) split Sampling splitting computing initial estimator. take effects beta.init =  NULL. (default = TRUE) lambda tuning parameter fitting initial model. NULL, picked cross-validation. (default = NULL) mu dual tuning parameter used construction projection direction. NULL searched automatically. (default = NULL) prob.filter threshold estimated probabilities filtering observations logistic regression. (default = 0.05) rescale factor enlarge standard error account finite sample bias. (default = 1.1) tau enlargement factor asymptotic variance bias-corrected estimator handle super-efficiency. allows scalar vector. (default = c(0.25,0.5)) alpha Level significance construct two-sided confidence interval (default = 0.05) verbose intermediate message(s) printed, projection direction returned. (default = FALSE)","code":""},{"path":"/reference/QF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inference for quadratic forms of the regression vector in high dimensional\r\ngeneralized linear regressions — QF","text":"est.plugin plugin(biased) estimator quadratic form regression vector restricted G est.debias bias-corrected estimator quadratic form regression vector se Standard errors bias-corrected estimator, length tau; corrsponding different values tau ci.mat matrix two.sided confidence interval quadratic form regression vector; row corresponds different values tau proj projection direction. returned verbose set TRUE","code":""},{"path":"/reference/QF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inference for quadratic forms of the regression vector in high dimensional\r\ngeneralized linear regressions — QF","text":"","code":"X = matrix(rnorm(100*5), nrow=100, ncol=5) y = X[,1] * 0.5 + X[,2] * 1 + rnorm(100) G = c(1,2) A = matrix(c(1.5, 0.8, 0.8, 1.5), nrow=2, ncol=2) Est = QF(X, y, G, A, model=\"linear\") ## compute confidence intervals ci(Est, alpha=0.05, alternative=\"two.sided\") #>    tau     lower    upper #> 1 0.25 0.9561798 3.301689 #> 2 0.50 0.8868846 3.370984  ## summary statistics summary(Est) #> Call:  #> Inference for Quadratic Functional #>  #>   tau est.plugin est.debias Std. Error z value  Pr(>|z|)     #>  0.25      1.704      2.129     0.5984   3.558 0.0003737 *** #>  0.50      1.704      2.129     0.6337   3.359 0.0007809 ***"},{"path":"/reference/summary.ITE.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing ITE — summary.ITE","title":"Summarizing ITE — summary.ITE","text":"`summary` method class `ITE`","code":""},{"path":"/reference/summary.ITE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing ITE — summary.ITE","text":"","code":"# S3 method for ITE summary(object, ...)"},{"path":"/reference/summary.ITE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing ITE — summary.ITE","text":"object object class `ITE`, result call `ITE` ... arguments pass ","code":""},{"path":"/reference/summary.ITE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing ITE — summary.ITE","text":"function `summary.ITE` computes returns list summary statistics. output.est \\(ncol(loading.mat)\\) x 7 matrix columns loading, plugin(biased) estimators, bias-corrected estimators, standard error, z-statistic, corresponding (two-sided) p-value significance stars; row corresponds loading.","code":""},{"path":"/reference/summary.ITE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarizing ITE — summary.ITE","text":"","code":"if (FALSE) { ##-- Continuing the ITE(.) example: sEst = summary(Est) sEst }"},{"path":"/reference/summary.LF.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing LF — summary.LF","title":"Summarizing LF — summary.LF","text":"`summary` method class `LF`","code":""},{"path":"/reference/summary.LF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing LF — summary.LF","text":"","code":"# S3 method for LF summary(object, ...)"},{"path":"/reference/summary.LF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing LF — summary.LF","text":"object object class `LF`, result call `LF` ... arguments pass ","code":""},{"path":"/reference/summary.LF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing LF — summary.LF","text":"function `summary.LF` computes returns list summary statistics. output.est \\(ncol(loading.mat)\\) x 7 matrix columns loading, plugin(biased) estimators, bias-corrected estimators, standard error, z-statistic, corresponding (two-sided) p-value significance stars; row corresponds loading.","code":""},{"path":"/reference/summary.LF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarizing LF — summary.LF","text":"","code":"if (FALSE) { ##-- Continuing the LF(.) example: sEst = summary(Est) sEst }"},{"path":"/reference/summary.QF.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing QF — summary.QF","title":"Summarizing QF — summary.QF","text":"`summary` method class `QF`","code":""},{"path":"/reference/summary.QF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing QF — summary.QF","text":"","code":"# S3 method for QF summary(object, ...)"},{"path":"/reference/summary.QF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing QF — summary.QF","text":"object object class `QF`, result call `QF` ... arguments pass ","code":""},{"path":"/reference/summary.QF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing QF — summary.QF","text":"function `summary.QF` computes returns list summary statistics. output.est \\(length(tau.vec)\\) x 7 matrix columns tau, plugin(biased) estimators, bias-corrected estimators, standard error, z-statistic, corresponding (two-sided) p-value significance stars; row corresponds tau.","code":""},{"path":"/reference/summary.QF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarizing QF — summary.QF","text":"","code":"if (FALSE) { ##-- Continuing the QF(.) example: sEst = summary(Est) sEst }"}]
